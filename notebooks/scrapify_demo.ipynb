{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j12YgYtdP9JK"
      },
      "source": [
        "# üï∏Ô∏è Scrapify\n",
        "\n",
        "<!-- [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YonaniCodes/Scrapify/blob/main/notebooks/scrapify-demo.ipynb) -->\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFTPeEs3P9JN",
        "outputId": "632b52ab-6041-4e64-a4b3-6088c33181e1",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into '/content/Scrapify'...\n",
            "remote: Enumerating objects: 92, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 92 (delta 34), reused 55 (delta 14), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (92/92), 22.09 KiB | 2.01 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Check if running in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Define repo path\n",
        "repo_url = \"https://github.com/YonaniCodes/Scrapify.git\"\n",
        "repo_path = \"/content/Scrapify\"\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Clone the repo only if it doesn't exist\n",
        "    if not os.path.exists(repo_path):\n",
        "        !git clone {repo_url} {repo_path}\n",
        "    else:\n",
        "        # Go into the repo and pull the latest changes\n",
        "        %cd {repo_path}\n",
        "\n",
        "        # Stash local changes if necessary to avoid conflicts with the pull\n",
        "        !git stash\n",
        "        !git pull\n",
        "        # Return to the root directory\n",
        "        %cd /content\n",
        "\n",
        "    # Add src/ to sys.path\n",
        "    sys.path.append(f\"{repo_path}/src\")\n",
        "else:\n",
        "    # Local path config for non-Colab environment\n",
        "    local_src_path = os.path.abspath(\"../src\")\n",
        "    sys.path.append(local_src_path)\n",
        "\n",
        "# Import the scraper function from the module\n",
        "\n",
        "\n",
        "# Call the scrape function (this will print \"Scraping..........\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsKMo2C6iv2Z",
        "outputId": "1738fb50-66b3-4d7d-ae43-0ca28d6b7409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "database.py  __init__.py  __pycache__  scrapify.py\n"
          ]
        }
      ],
      "source": [
        "!ls /content/Scrapify/src\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mHBeY02j0Qr",
        "outputId": "f34add65-62c2-43f7-befb-10faffd333cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_data  Scrapify\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIjTuB3dlScG",
        "outputId": "4cc26ae4-a994-42aa-faa1-797777ae16ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Scrapify\n"
          ]
        }
      ],
      "source": [
        "%cd Scrapify\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqqekac2l0DP",
        "outputId": "c0265d24-f552-49ae-d4f4-77f42b8016a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting asgiref==3.8.1 (from -r requirements.txt (line 1))\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting asttokens==2.4.1 (from -r requirements.txt (line 2))\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting blinker==1.8.2 (from -r requirements.txt (line 3))\n",
            "  Downloading blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: CacheControl==0.14.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.14.2)\n",
            "Requirement already satisfied: cachetools==5.5.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (5.5.2)\n",
            "Collecting certifi==2024.8.30 (from -r requirements.txt (line 6))\n",
            "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: cffi==1.17.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.17.1)\n",
            "Requirement already satisfied: charset-normalizer==3.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (3.4.1)\n",
            "Collecting click==8.1.7 (from -r requirements.txt (line 9))\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting colorama==0.4.6 (from -r requirements.txt (line 10))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting comm==0.2.2 (from -r requirements.txt (line 11))\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting contourpy==1.2.1 (from -r requirements.txt (line 12))\n",
            "  Downloading contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting cryptography==44.0.2 (from -r requirements.txt (line 13))\n",
            "  Downloading cryptography-44.0.2-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (0.12.1)\n",
            "Collecting debugpy==1.8.1 (from -r requirements.txt (line 15))\n",
            "  Downloading debugpy-1.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting decorator==5.1.1 (from -r requirements.txt (line 16))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting distlib==0.3.9 (from -r requirements.txt (line 17))\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting Django==5.1.3 (from -r requirements.txt (line 18))\n",
            "  Downloading Django-5.1.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting executing==2.0.1 (from -r requirements.txt (line 19))\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting filelock==3.16.1 (from -r requirements.txt (line 20))\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: firebase-admin==6.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (6.7.0)\n",
            "Collecting Flask==3.0.3 (from -r requirements.txt (line 22))\n",
            "  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting fonttools==4.52.4 (from -r requirements.txt (line 23))\n",
            "  Downloading fonttools-4.52.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (161 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core==2.24.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (2.24.2)\n",
            "Collecting google-api-python-client==2.166.0 (from -r requirements.txt (line 25))\n",
            "  Downloading google_api_python_client-2.166.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: google-auth==2.38.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (0.2.0)\n",
            "Requirement already satisfied: google-cloud-core==2.4.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (2.4.3)\n",
            "Requirement already satisfied: google-cloud-firestore==2.20.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 29)) (2.20.1)\n",
            "Collecting google-cloud-storage==3.1.0 (from -r requirements.txt (line 30))\n",
            "  Downloading google_cloud_storage-3.1.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: google-crc32c==1.7.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 31)) (1.7.1)\n",
            "Requirement already satisfied: google-resumable-media==2.7.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (2.7.2)\n",
            "Requirement already satisfied: googleapis-common-protos==1.69.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 33)) (1.69.2)\n",
            "Requirement already satisfied: grpcio==1.71.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 34)) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status==1.71.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 35)) (1.71.0)\n",
            "Requirement already satisfied: httplib2==0.22.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 36)) (0.22.0)\n",
            "Requirement already satisfied: idna==3.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 37)) (3.10)\n",
            "Collecting ipykernel==6.29.4 (from -r requirements.txt (line 38))\n",
            "  Downloading ipykernel-6.29.4-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting ipython==8.24.0 (from -r requirements.txt (line 39))\n",
            "  Downloading ipython-8.24.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: itsdangerous==2.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 40)) (2.2.0)\n",
            "Collecting jedi==0.19.1 (from -r requirements.txt (line 41))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting Jinja2==3.1.4 (from -r requirements.txt (line 42))\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: joblib==1.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 43)) (1.4.2)\n",
            "Collecting jupyter_client==8.6.2 (from -r requirements.txt (line 44))\n",
            "  Downloading jupyter_client-8.6.2-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: jupyter_core==5.7.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 45)) (5.7.2)\n",
            "Collecting kiwisolver==1.4.5 (from -r requirements.txt (line 46))\n",
            "  Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting MarkupSafe==2.1.5 (from -r requirements.txt (line 47))\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting matplotlib==3.9.0 (from -r requirements.txt (line 48))\n",
            "  Downloading matplotlib-3.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.7 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 49)) (0.1.7)\n",
            "Requirement already satisfied: msgpack==1.1.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 50)) (1.1.0)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 51)) (1.6.0)\n",
            "Collecting numpy==1.26.4 (from -r requirements.txt (line 52))\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==24.0 (from -r requirements.txt (line 53))\n",
            "  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 54)) (2.2.2)\n",
            "Requirement already satisfied: parso==0.8.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 55)) (0.8.4)\n",
            "Collecting pdf2image==1.17.0 (from -r requirements.txt (line 56))\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pillow==10.3.0 (from -r requirements.txt (line 57))\n",
            "  Downloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pipenv==2024.4.0 (from -r requirements.txt (line 58))\n",
            "  Downloading pipenv-2024.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting platformdirs==4.2.2 (from -r requirements.txt (line 59))\n",
            "  Downloading platformdirs-4.2.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting prompt_toolkit==3.0.45 (from -r requirements.txt (line 60))\n",
            "  Downloading prompt_toolkit-3.0.45-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: proto-plus==1.26.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 61)) (1.26.1)\n",
            "Requirement already satisfied: protobuf==5.29.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 62)) (5.29.4)\n",
            "Collecting psutil==5.9.8 (from -r requirements.txt (line 63))\n",
            "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting pure-eval==0.2.2 (from -r requirements.txt (line 64))\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pyasn1==0.6.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 65)) (0.6.1)\n",
            "Requirement already satisfied: pyasn1_modules==0.4.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 66)) (0.4.2)\n",
            "Requirement already satisfied: pycparser==2.22 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 67)) (2.22)\n",
            "Requirement already satisfied: Pygments==2.18.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 68)) (2.18.0)\n",
            "Requirement already satisfied: PyJWT==2.10.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 69)) (2.10.1)\n",
            "Collecting pyparsing==3.1.2 (from -r requirements.txt (line 70))\n",
            "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pytesseract==0.3.13 (from -r requirements.txt (line 71))\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting python-dateutil==2.9.0.post0 (from -r requirements.txt (line 72))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz==2024.1 (from -r requirements.txt (line 73))\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32==306 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pywin32==306\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb06iS-9l99j",
        "outputId": "687163f6-1de8-42b0-eb9f-a6192e6f11c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Everything is ready you can start working üéâüéâüéâüéâ\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "\n",
        "# Get output of ls command\n",
        "output = subprocess.check_output(\"ls\", shell=True).decode().splitlines()\n",
        "\n",
        "# Now you can conditionally check\n",
        "if \"firebase-adminsdk.json\" in output:\n",
        "    print(\"Everything is ready you can start working üéâüéâüéâüéâ\")\n",
        "else:\n",
        "    print(\"firebase-adminsdk.json not found.üòíüòíüòí please ask Yonani for the file\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6o8Mma6mGxT",
        "outputId": "d18de348-d63a-4a55-9c48-7e6c5cdca00b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/google/cloud/firestore_v1/base_collection.py:303: UserWarning: Detected filter using positional arguments. Prefer using the 'filter' keyword argument instead.\n",
            "  return query.where(field_path, op_string, value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå This website has already been scraped: https://yonasawoke\n",
            "‚ùå This website has already been registered: https://yonasawoke\n",
            "Scraped Websites:\n",
            "{'url': 'https://yonasawoke', 'scraper': 'Yonas Awoke', 'timestamp': DatetimeWithNanoseconds(2025, 4, 9, 11, 22, 40, 867000, tzinfo=datetime.timezone.utc)}\n",
            "{'url': 'https://helllo', 'scraper': 'yonas', 'timestamp': 'No timestamp available'}\n",
            "{'url': 'https://yonasawokewee', 'scraper': 'yonas', 'timestamp': DatetimeWithNanoseconds(2025, 4, 9, 13, 25, 25, 755000, tzinfo=datetime.timezone.utc)}\n",
            "Unscraped Websites:\n",
            "{'url': 'https://yonasawoke', 'timestamp': DatetimeWithNanoseconds(2025, 4, 9, 11, 29, 8, 86000, tzinfo=datetime.timezone.utc)}\n",
            "{'url': 'https://yonasawokekkkkkkkkkkkkkkk', 'timestamp': DatetimeWithNanoseconds(2025, 4, 9, 13, 25, 8, 257000, tzinfo=datetime.timezone.utc)}\n",
            "Scraping..........\n"
          ]
        }
      ],
      "source": [
        "from src.scrapify import scrape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VLL-FMimKTP",
        "outputId": "4d28de87-8d06-4372-d120-1e252c51cc09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/google/cloud/firestore_v1/base_collection.py:303: UserWarning: Detected filter using positional arguments. Prefer using the 'filter' keyword argument instead.\n",
            "  return query.where(field_path, op_string, value)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå This website has already been scraped: https://yonasawoke\n",
            "‚ùå This website has already been registered: https://yonasawoke\n",
            "Scraped Websites:\n",
            "{'url': 'https://yonasawoke', 'scraper': 'Yonas Awoke', 'timestamp': DatetimeWithNanoseconds(2025, 4, 9, 11, 22, 40, 867000, tzinfo=datetime.timezone.utc)}\n",
            "{'url': 'https://helllo', 'scraper': 'yonas', 'timestamp': 'No timestamp available'}\n",
            "Unscraped Websites:\n",
            "{'url': 'https://yonasawoke', 'timestamp': DatetimeWithNanoseconds(2025, 4, 9, 11, 29, 8, 86000, tzinfo=datetime.timezone.utc)}\n",
            "Scraping..........nnnnnnnnnnn\n"
          ]
        }
      ],
      "source": [
        "scrape()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaUyoeqXm6hX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
