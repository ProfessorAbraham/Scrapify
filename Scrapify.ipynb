{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVF_oaIimEVy",
        "outputId": "e5d38c1a-6b30-4ecf-b908-1374aefd8bc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.11/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect) (1.17.0)\n",
            "Requirement already satisfied: langid in /usr/local/lib/python3.11/dist-packages (1.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from langid) (2.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect\n",
        "!pip install langid\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import json\n",
        "from langdetect import detect\n",
        "import uuid\n",
        "import os\n",
        "from pathlib import Path\n",
        "import langid\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from langdetect import detect\n",
        "import langid\n",
        "\n",
        "class AmharicTextScraper:\n",
        "    def __init__(self, url, jsonl_path,filename=\"webpage_amharic_text.jsonl\"):\n",
        "        self.url = url\n",
        "        self.jsonl_path = jsonl_path\n",
        "        self.amharic_text = []\n",
        "        self.page_content = None\n",
        "        self.jsonl_path = jsonl_path\n",
        "        self.file_name=filename\n",
        "\n",
        "    def fetch_page(self):\n",
        "        # headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "        response = requests.get(self.url, headers=headers)\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Failed to access {self.url}, Status Code: {response.status_code}\")\n",
        "            return self\n",
        "\n",
        "        if langid.classify(response.text)[0] != \"am\":\n",
        "            print(f\"The page at {self.url} is not detected as Amharic.\")\n",
        "            return self\n",
        "\n",
        "        self.page_content = response.text\n",
        "        return self\n",
        "\n",
        "    def extract_amharic_text(self):\n",
        "        if not self.page_content:\n",
        "            print(\"No page content to process\")\n",
        "            return self\n",
        "\n",
        "        soup = BeautifulSoup(self.page_content, \"html.parser\")\n",
        "        paragraphs = soup.find_all(\"p\")\n",
        "\n",
        "        for p in paragraphs:\n",
        "            text = p.get_text(strip=True)\n",
        "            if not text:\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                lang, confidence = langid.classify(text)\n",
        "                if (lang == \"am\" and confidence > -50) or self.is_probably_amharic(text):\n",
        "                    self.amharic_text.append(text)\n",
        "            except Exception as e:\n",
        "                print(\"Language detection failed:\", e)\n",
        "                pass\n",
        "\n",
        "        return self\n",
        "\n",
        "    def is_probably_amharic(self, text):\n",
        "        # Checks if any character is in the Amharic Unicode block\n",
        "        return any('\\u1200' <= char <= '\\u137F' for char in text)\n",
        "\n",
        "    def save_to_jsonl(self):\n",
        "        path = os.path.join(self.jsonl_path, self.file_name)\n",
        "         # Create the directory if it doesn't exist\n",
        "        os.makedirs(self.jsonl_path, exist_ok=True)\n",
        "\n",
        "        with open(path, 'a', encoding='utf-8') as f:\n",
        "            for text in self.amharic_text:\n",
        "                json.dump({'url': self.url, 'text': text}, f, ensure_ascii=False)\n",
        "                f.write(\"\\n\")\n",
        "        print(f\"Extracted Amharic text saved to {self.jsonl_path}\")\n",
        "        return self\n",
        "\n",
        "    def run(self):\n",
        "        return self.fetch_page().extract_amharic_text().save_to_jsonl()\n"
      ],
      "metadata": {
        "id": "YRd1yWVbu34z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "page_url = \"https://www.fanamc.com/archives/288627\"\n",
        "text=AmharicTextScraper(page_url,\"drive/MyDrive/scraped_data\",\"amharic.jsonl\").run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-SmBeD4wrNz",
        "outputId": "e8d6a684-83ad-4602-9404-eeab47c14e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Amharic text saved to drive/MyDrive/scraped_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n",
        "import pymupdf as fitz\n",
        "class AmharicPDFFetcher:\n",
        "    def __init__(self, pdf_url, save_dir, file_name=\"amharic_from_pdf.jsonl\"):\n",
        "        self.pdf_url = pdf_url\n",
        "        self.save_dir = Path(save_dir)\n",
        "        self.file_name = file_name\n",
        "        self.amharic_texts = []\n",
        "\n",
        "        # Create the save directory if it doesn't exist\n",
        "        self.save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def download_pdf(self):\n",
        "        response = requests.get(self.pdf_url)\n",
        "        if response.status_code != 200:\n",
        "            raise Exception(f\"Failed to download PDF. Status code: {response.status_code}\")\n",
        "\n",
        "        self.pdf_path = self.save_dir / \"temp.pdf\"\n",
        "        with open(self.pdf_path, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        print(f\"✅ PDF downloaded to {self.pdf_path}\")\n",
        "        return self\n",
        "\n",
        "    def extract_amharic_text(self):\n",
        "      amharic_re = re.compile(r'[\\u1200-\\u137F]+')\n",
        "      doc = fitz.open(self.pdf_path)\n",
        "      for page in doc:\n",
        "          text = page.get_text()\n",
        "          for line in text.splitlines():\n",
        "              line = line.strip()\n",
        "              if line and amharic_re.search(line):\n",
        "                  self.amharic_texts.append(line)\n",
        "      doc.close()\n",
        "      print(f\"✅ Extracted {len(self.amharic_texts)} Amharic lines.\")\n",
        "      return self\n",
        "\n",
        "    def save_to_jsonl(self):\n",
        "        output_path = self.save_dir / self.file_name\n",
        "        with open(output_path, \"a\", encoding=\"utf-8\") as f:\n",
        "            for line in self.amharic_texts:\n",
        "                json.dump({'url': self.pdf_url, 'text': line}, f, ensure_ascii=False)\n",
        "                f.write(\"\\n\")\n",
        "        print(f\"✅ Saved to {output_path}\")\n",
        "        return self\n",
        "\n",
        "    def run(self):\n",
        "        return self.download_pdf().extract_amharic_text().save_to_jsonl()\n"
      ],
      "metadata": {
        "id": "zfUsY4iD_yLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77d4ea30-3146-4d46-be1c-beb5659e3353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = Path(\"/content/drive/MyDrive/scraped_pdfs\")\n",
        "file_name = \"amharic_output.jsonl\"\n",
        "\n",
        "Pdf_urls = [\n",
        "    \"https://laws.moj.gov.et/sites/default/files/registry/cae0761a-ef52-48c9-b992-8364128730ec.pdf\",\n",
        "    \"https://mols.gov.et/wp-content/uploads/2022/07/Labour-proclamation-1156.pdf\",\n",
        "    \"https://fjli.gov.et/researches/Research42.pdf\",\n",
        "    \"https://nbe.gov.et/wp-content/uploads/2023/04/Reinsurance-Company-Establishment.pdf\",\n",
        "    \"https://fjli.gov.et/researches/Research23.pdf\",\n",
        "    \"https://fjli.gov.et/researches/Research27.pdf\"\n",
        "]\n",
        "\n",
        "for pdf_url in Pdf_urls:\n",
        "    try:\n",
        "        scraper = AmharicPDFFetcher(pdf_url, save_dir, file_name)\n",
        "        scraper.run()\n",
        "    except Exception as e:\n",
        "        print(\"Failed to download file:\", pdf_url)\n",
        "        pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWWzptWkCyBr",
        "outputId": "f8b5223d-706b-4505-c5c6-b0ba4d2bca71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ PDF downloaded to /content/drive/MyDrive/scraped_pdfs/temp.pdf\n",
            "✅ Extracted 477 Amharic lines.\n",
            "✅ Saved to /content/drive/MyDrive/scraped_pdfs/amharic_output.jsonl\n",
            "✅ PDF downloaded to /content/drive/MyDrive/scraped_pdfs/temp.pdf\n",
            "✅ Extracted 0 Amharic lines.\n",
            "✅ Saved to /content/drive/MyDrive/scraped_pdfs/amharic_output.jsonl\n",
            "Failed to download file: https://fjli.gov.et/researches/Research42.pdf\n",
            "✅ PDF downloaded to /content/drive/MyDrive/scraped_pdfs/temp.pdf\n",
            "✅ Extracted 0 Amharic lines.\n",
            "✅ Saved to /content/drive/MyDrive/scraped_pdfs/amharic_output.jsonl\n",
            "Failed to download file: https://fjli.gov.et/researches/Research23.pdf\n",
            "Failed to download file: https://fjli.gov.et/researches/Research27.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GHNw-vf6Dgfw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}